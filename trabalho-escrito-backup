Compressão de dados utilizando codificação de Huffman 

 

Adriner Maranho de Andrade 

Luan Carlos Purin 

 

Abstract. As technology advances, the data volume being created is increasing impressively. We must look for alternatives that can represent the data we have in a simpler way, that is, reducing their representation, but having the same logical value. One alternative for this is the Huffman coding algorithm, developed in this article. 

 

Resumo. Conforme o avanço da tecnologia, o volume de dados sendo criado vem crescendo de maneira impressionante. É preciso então buscar alternativas que possam representar os dados que temos de maneira mais simples, isto é, reduzir sua representação, mas possuindo o mesmo valor lógico.  Uma das alternativas para essa questão é o algoritmo de codificação de Huffman, desenvolvido nesse artigo. 

 

Introdução 

 

A partir do momento que evoluímos tecnologicamente e construímos sistemas mais robustos, aumentamos a quantidade de dados produzidos. O aumento da qualidade de determinados setores da computação está intimamente ligado com a riqueza de detalhes e características, como imagens, que são convertidos por nós em bytes. Além disso, o fato de estarmos sempre otimizando os hardwares, tanto de memória quanto de processamento, nesse processo de evolução e a disponibilização desses mesmos recursos em nuvem, criou uma cultura, principalmente no meio empresarial, onde a quantidade de dados não é mais uma preocupação tão grande no momento da construção de um software pelos desenvolvedores, pois possui alta disponibilidade e com baixo custo. Iniciativas como big data também fomentam todo esse processo. 

 

Com essa quantidade de dados, além de as vezes realmente precisarmos economizar um pouco de memória, temos o problema para realizarmos sua transferência, como por exemplo, o download/upload de arquivos ou então o envio de uma aplicação para funcionar em nuvem. Enviando esses arquivos em sua forma original pode demorar muito, devido ao tráfego da rede e o tamanho do arquivo. Para solucionar problemas como esse se utiliza então a compactação. 

 

Entre vários tipos de compactação, analisaremos mais a seguir a codificação de Huffman. 

 

Desenvolvimento 

 

A compactação se constrói em cima de uma árvore binária, que segundo STIX (1991) foi provado matematicamente por Huffman como a forma mais eficiente de demonstrar dados com valores binários através de uma combinação de probabilidades das frequências de cada valor. A codificação de Huffman é muito utilizada até hoje para compactação de textos. Conforme MORRIS (1998) da universidade de Auckland, é necessário montar uma árvore em que letras de maiores frequências fiquem perto da raiz de modo que possuam um prefixo único. Para isso, é necessário que todas as letras sejam uma folha da árvore. 

 

A execução do programa desenvolvido começa a partir da leitura de um arquivo informado pelo usuário. Nesse momento são mapeadas a frequência das letras, e a partir disso é criada representação de cada caractere de maneira única. O programa de codificação, feito em JAVA, possui um padrão de 8 bits para cada caractere, podendo expandir para 16 bits caso for especial (ã, por exemplo). 

 

<construir exemplo com palavra maçã> 

 

Após a realização da codificação, quebramos a codificação gerada pela árvore em um vetor de bytes, já que teoricamente essa seria a unidade utilizada para transferência de arquivos. Uma cadeia de valor 1000100101010011 gerada, seria transformada em um vetor com dois bytes [10001001, 01010011] = [137, 83]. 

 

Um problema surge quando geramos uma cadeia em que o seu tamanho não é divisível por 8. Considerando um cenário onde temos a = 0 e b = 1, o seguinte texto "ababababaabb" seria convertido para 010101010011, em que teremos [01010101, 0011]. Observe que no último valor temos o equivalente ao número 3, porém não podemos simplesmente transformar o binário em byte, pois não estaremos o informando com precisão. Caso o binário for gerado com exatamente esses valores, poderemos estar perdendo dados no momento da descodificação. Considere que salvamos o vetor como [85, 3], no momento da leitura, o valor que deveria ser obtido como 0011 será obtido como apenas 11. Se forçarmos também para obtermos o byte 3 com tamanho de 8 bits (acrescendo os zeros a esquerda), estaremos colocando 0's adicionas e teremos então 00000011, que será "aaaaaabb" e não "aabb".  

 

Para solucionar o problema foi criado um byte adicional que informa a quantidade de zeros a direita para completar o byte, ou seja, a quantidade de bits a serem ignorados no último byte no momento da leitura. No caso do exemplo apresentado acima, o valor 0011 será representado como 00110000. Assim, o vetor resultante da codificação será [4, 85, 48] ao invés de [85, 3]. O primeiro valor do vetor se refere a quantos bits faltavam para completar um byte, no caso 4, o resto do vetor são de fato os valores já convertidos em byte. Ignorar a quantidade de bits informada no primeiro byte é crucial para o funcionamento da codificação também, já que o valor apresentado acima (00110000) poderia ser interpretado também como "aabbaaaa", quando sem os bits adicionais temos exatamente "aabb". 

 

A etapa de decodificação se desenvolve percorrendo a árvore encontrando as folhas que determinaram o prefixo único para cada letra e montando novamente o texto, guardando a saída em um arquivo chamado output.txt. 

 

Referências 

 

STIX, Gary. Scientific American Article: Encoding the “Neatness” of Ones and Zeroes. 1991. Disponível em: <https://www.huffmancoding.com/my-uncle/scientific-american>. Acesso em: 18 mar. 2018. 

 

MORRIS, John. Huffman Encoding. 1998. Disponível em: <https://www.cs.auckland.ac.nz/software/AlgAnim/huffman.html>. Acesso em: 19 mar. 2018. 

 

 
